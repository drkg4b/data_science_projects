{"cells":[{"source":["from sklearn.pipeline import make_pipeline\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import RandomizedSearchCV, cross_validate\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.utils import resample\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, roc_auc_score, roc_curve\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","import itertools\n","import os\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.style.use(['ggplot', 'seaborn'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["in_dir = 'data'\n","\n","in_data = os.path.join(in_dir, 'employee-attrition.csv')\n","\n","df = pd.read_csv(in_data)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["df.info()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" there aren't any missing values and out target variable appears to be categorical."],"metadata":{}},{"source":["df.describe().T\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["df.sample(10)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" There are only two possible values for the target variable and it is highly imbalanced, will need to balance it before training the model. Let us transform it into numeric."],"metadata":{}},{"source":["data = df['Attrition'].value_counts()\n","\n","_ = sns.barplot(data.index, data.values, palette='muted')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["df.loc[df['Attrition'] == 'Yes', 'Attrition'] = 1\n","df.loc[df['Attrition'] == 'No', 'Attrition'] = 0\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Let us check correlation between variables."],"metadata":{}},{"source":["corr = df.corr()\n","\n","fig, ax = plt.subplots(figsize=(15, 15))\n","\n","sns.heatmap(corr, cmap='coolwarm', annot=True, fmt='.2f', linewidths=.5, ax=ax)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["abs(corr['Attrition']) > 0.5\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" There don't seem to be high correlation between any of the variables and the target one but some features are highly correlated with each other and worth investigating more to see if they can be dropped. In particular:\n"," - JobLevel almost has perfect correlation with MonthlyIncome\n"," - EmployeeCount and StandardHours have the same number in it and can probably be dropped from the dataset.\n"," - Age higly correlates with JobLevel, MonthlyIncome and TotalWorkingYears\n"," - JobLevel highly correlates with TotalWorkingYears and YearsAtCompany\n"," - MonthlyIncome highly correlates with TotalWorkingYears and YearsAtCompany\n"," - PercentSalaryHike highly correlates with PerformanceRating\n"," Let us check the categorical features"],"metadata":{}},{"source":["df.describe(include=['O'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" It appears that Over18 only have one value and can be dropped from the dataset."],"metadata":{}},{"source":["to_drop = ['EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber']\n","\n","df.drop(columns=to_drop, inplace=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","\n","def PlotDists(feature, position):\n","    '''\n","    '''\n","    g = sns.factorplot(x=feature, y='Attrition',\n","                       data=df, palette='muted', kind='bar', size=6, ax=position)\n","\n","    g.despine(left=True)\n","\n","    g = g.set_ylabels('Attrition probability')\n","\n","    # This is needed, see: https://stackoverflow.com/questions/33925494/seaborn-produces-separate-figures-in-subplots\n","    plt.close(g.fig)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["to_plot = ['BusinessTravel', 'Department', 'EducationField', 'Gender',\n","           'JobRole', 'MaritalStatus', 'OverTime']\n","\n","fig, ax = plt.subplots(4, 2, figsize=(20, 20), sharex=False, sharey=False)\n","\n","# Flatten out the axis object\n","ax = ax.ravel()\n","\n","for i in range(7):\n","\n","    PlotDists(to_plot[i], ax[i])\n","\n","plt.tight_layout()\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" - Looks like that people who trave more frequently are more likely to quit compared to those who don't travel or travel rarely.\n"," - People in the sales department are more likely to quit although HR has a high standard deviation.\n"," - Male quit more often than women.\n"," - Sales representatives have the highest probability to quit.\n"," - Singles are more likely to quit compared to married or divorced employees.\n"," - People doing overtime have a high probability to quit.\n","\n"," Would be nice to study more the relationship between the features but for time constraints I will come back to it if I have some time left."],"metadata":{}},{"source":["# Get numerical and categorical features\n","numerical = df.select_dtypes(exclude=['object'])\n","categorical = df.select_dtypes(['object'])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Convert BusinessTravel into an ordinal categorical variable since there is intrinsic order between non, rarely and frequently.\n"," One hot encode the remaining variables.\n"," One hot encode categorical features"],"metadata":{}},{"cell_type":"markdown","source":[" We saw that the Attrition class is imbalanced. As a consequence accuracy is not a good metric anymore and we should use other metrics when comparing models such as recall, f1-score or AUC. Moreover most algorithms will learn patterns that will be biased towards the majority class.\n"," We can deal with imbalanced classes by:\n"," - Assign a bigger penalty to wrong predictions from the minority class.\n"," - Upsampling the minority class or downsampling the majority one.\n"," - Simulate more data.\n"," A penalty for wrong predictios for the minority class can be assigned in some of the algorithms using the `class_weight` parameter.\n"," We need to split our dataset before oversampling because in this case, the same observation can be repeated in both the training and test sets causing the model to simply learn some specific datapoints and thus overfit."],"metadata":{}},{"source":["# Split the dataset\n","X = df.drop('Attrition', axis=1)\n","y = df['Attrition']\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=.2, random_state=42, stratify=y)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Oversampling the minority class\n","X_train_up, y_train_up = resample(X_train[y_train == 1],\n","                                  y_train[y_train == 1],\n","                                  replace=True,\n","                                  n_samples=X_train[y_train == 0].shape[0],\n","                                  random_state=1)\n","\n","X_train_up = pd.concat([X_train[y_train == 0], X_train_up])\n","y_train_up = pd.concat([y_train[y_train == 0], y_train_up])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Downsample majority class\n","X_train_dw, y_train_dw = resample(X_train[y_train == 0],\n","                                  y_train[y_train == 0],\n","                                  replace=True,\n","                                  n_samples=X_train[y_train == 1].shape[0],\n","                                  random_state=1)\n","\n","X_train_dw = pd.concat([X_train[y_train == 1], X_train_dw])\n","y_train_dw = pd.concat([y_train[y_train == 1], y_train_dw])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Check the shapes of the classes\n","print(\"Original shape:\", X_train.shape, y_train.shape)\n","print(\"Upsampled shape:\", X_train_up.shape, y_train_up.shape)\n","print(\"Downsampled shape:\", X_train_dw.shape, y_train_dw.shape)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Check the principal components\n","\n","pca = PCA(n_components=None, svd_solver=\"full\")\n","\n","scaler = StandardScaler()\n","scaler = scaler.fit_transform(X_train)\n","\n","pca.fit(scaler)\n","\n","cum_var_exp = np.cumsum(pca.explained_variance_ratio_)\n","\n","plt.figure(figsize=(12, 6))\n","\n","n_features = len(cum_var_exp) + 1\n","\n","plt.bar(range(1, n_features), pca.explained_variance_ratio_, align=\"center\",\n","        color='magenta', label=\"Individual explained variance\")\n","\n","plt.step(range(1, n_features), cum_var_exp, where=\"mid\",\n","         label=\"Cumulative explained variance\", color='blue')\n","\n","plt.xticks(range(1, n_features))\n","plt.legend(loc=\"best\")\n","\n","plt.xlabel(\"Principal component index\", {\"fontsize\": 14})\n","plt.ylabel(\"Explained variance ratio\", {\"fontsize\": 14})\n","plt.title(\"PCA on training data\", {\"fontsize\": 16})\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["print('We need', np.where(cum_var_exp > 0.90)[\n","      0][0], 'features to explain 90% of the variation of the data.')\n","print('We need', np.where(cum_var_exp > 0.95)[\n","      0][0], 'features to explain 95% of the variation of the data.')\n","print('We need', np.where(cum_var_exp > 0.99)[\n","      0][0], 'features to explain 99% of the variation of the data.')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Since there are some redundant features we can use some algorithm to make a rank of the feature importance and decide which one we should remove."],"metadata":{}},{"source":["\n","# Preparing the parameters grid\n","# Number of trees in the random forest\n","n_estimators = [int(n) for n in np.linspace(200, 1000, 100)]\n","\n","# Number of features to consider at each split\n","max_features = ['auto', 'sqrt', 'log2']\n","\n","# Maximum number of levels in tree\n","max_depth = [int(n) for n in np.linspace(10, 100, 10)]\n","max_depth.append(None)\n","\n","# Minimum number of samples required to split a node\n","min_samples_split = [2, 5, 10]\n","\n","# Minimum number of leaf required at each node\n","min_samples_leaf = [1, 2, 4]\n","\n","# Method of selecting each samples for training each tree\n","bootstrap = [True, False]\n","\n","# Construct the grid\n","param_grid = {\n","    'n_estimators': n_estimators,\n","    'max_features': max_features,\n","    'max_depth': max_depth,\n","    'min_samples_split': min_samples_split,\n","    'min_samples_leaf': min_samples_leaf,\n","    'bootstrap': bootstrap\n","}\n","\n","datasets = {'imbalanced': (X_train, y_train),\n","            'up_sampled': (X_train_up, y_train_up),\n","            'dw_sampled': (X_train_dw, y_train_dw)}\n","\n","for dataset in datasets:\n","\n","    pipeline = make_pipeline(StandardScaler(),\n","                             RandomForestClassifier(n_estimators=200,\n","                                                    class_weight='balanced',\n","                                                    random_state=42))\n","\n","    gs_rf = RandomizedSearchCV(pipeline, param_grid=param_grid, scoring='f1', cv=10, n_jobs=-1)                                                    \n","\n","    gs_rf.fit(datasets[dataset][0], datasets[dataset][1])\n","\n","    print(\"\\033[1m\" + \"\\033[0m\" + \"The best hyperparameters for {} data:\".format(datasets))\n","    for hyperparam in gs_rf.best_params_.keys():\n","        print(hyperparam[hyperparam.find(\"__\") + 2:], \": \", gs_rf.best_params_[hyperparam])\n","        \n","    print(\"\\033[1m\" + \"\\033[94m\" + \"Best 10-folds CV f1-score: {:.2f}%.\".format((gs_rf.best_score_) * 100))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","lr = LogisticRegression()\n","\n","lr.fit(X_train, y_train)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Predict on test set\n","lr_pred = lr.predict(X_test)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Accuracy can be misleading when dealing with imbalanced classes, we can use instead:\n"," - Confusion Matrix: a table showing correct predictions and types of incorrect predictions.\n"," - Precision: the number of true positives divided by all positive predictions. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n"," - Recall or true positive rate: the number of true positives divided by the number of positive values in the test data. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n"," - F1 Score: the weighted average of precision and recall.\n"," Since our main objective with the dataset is to prioritize accuraltely classifying fraud cases the recall score can be considered our main metric to use for evaluating outcomes."],"metadata":{}},{"source":["# Check some metrics\n","accuracy_score(y_test, lr_pred)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["f1_score(y_test, lr_pred)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["cm_lr = pd.DataFrame(confusion_matrix(y_test, lr_pred), index=[\n","                     'Attrition', 'No Attrition'], columns=['Attrition', 'No Attrition'])\n","\n","_ = sns.heatmap(cm_lr, cmap='coolwarm', annot=True,\n","                fmt='g', linewidths=.5, cbar=False)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["recall_score(y_test, lr_pred)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["lr.feature_importances_\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Next steps:\n"," - Implement RandomForrest\n"," - Use eithr random forrest of logistic regression to get a ranking of the variables and exclude redundant ones\n"," - Scale first just numeric and after numeric plus encoded variables to see performance\n"," Balance classes: oversampling, undersampling and penalyzing classes with `class_weight`\n"," PCA to see if we can reduce the dataset\n"," Train several models and evaluate the best performing ones.\n"," Use cross validation and GridSearchCV or RandomizedSearchCV."],"metadata":{}},{"cell_type":"markdown","source":[""],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}